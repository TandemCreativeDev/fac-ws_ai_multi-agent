from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, START, END
from typing import TypedDict
from dotenv import load_dotenv
from utils import ParallelCodebase
import time

load_dotenv()


class CodeAnalysisState(TypedDict):
    input: str
    code: str
    security_analysis: str
    performance_analysis: str
    style_analysis: str
    documentation_analysis: str
    final_report: str
    sequential_time: float
    parallel_time: float


llm = ChatOpenAI(model="gpt-4.1-nano")

coder_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a Senior Software Engineer. Write ONLY Python code - no bash commands, no installation instructions, just the Python implementation."),
    ("human", "{input}")
])

security_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a Security Expert. Analyse code for security vulnerabilities, input validation, and potential attack vectors."),
    ("human", "Analyse this code for security issues:\n{code}")
])

performance_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a Performance Expert. Analyse code for efficiency, algorithmic complexity, and optimisation opportunities."),
    ("human", "Analyse this code for performance issues:\n{code}")
])

style_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a Code Style Expert. Analyse code for PEP 8 compliance, naming conventions, and code organisation."),
    ("human", "Analyse this code for style and readability issues:\n{code}")
])

documentation_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a Documentation Expert. Generate comprehensive docstrings for functions and classes following PEP 257 conventions."),
    ("human", "Generate proper docstrings for this code:\n{code}")
])

synthesis_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a Technical Lead. Synthesise analysis reports into actionable recommendations with priorities. IMPORTANT: Security issues should be given 2x weight - treat security recommendations as highest priority."),
    ("human",
     "SECURITY ANALYSIS (HIGH PRIORITY - 2x weight):\n{security}\n\nPerformance Analysis:\n{performance}\n\nStyle Analysis:\n{style}\n\nDocumentation Analysis:\n{documentation}\n\nProvide prioritised recommendations with security concerns at the top:")
])


def measure_sequential_execution(code: str) -> float:
    start_time = time.time()

    llm.invoke(security_prompt.format_messages(code=code))
    llm.invoke(performance_prompt.format_messages(code=code))
    llm.invoke(style_prompt.format_messages(code=code))
    llm.invoke(documentation_prompt.format_messages(code=code))

    return time.time() - start_time


def coder_agent(state: CodeAnalysisState) -> CodeAnalysisState:
    response = llm.invoke(coder_prompt.format_messages(input=state["input"]))

    print("⏱️  Measuring sequential execution...")
    sequential_time = measure_sequential_execution(response.content)
    print(f"Sequential execution time: {sequential_time:.2f}s")

    return {"code": response.content, "sequential_time": sequential_time}


def security_agent(state: CodeAnalysisState) -> CodeAnalysisState:
    try:
        response = llm.invoke(
            security_prompt.format_messages(code=state["code"]))
        return {"security_analysis": response.content}
    except Exception as e:
        print(f"⚠️  Security agent failed: {str(e)}")
        return {"security_analysis": "Security analysis failed - agent encountered an error"}


def performance_agent(state: CodeAnalysisState) -> CodeAnalysisState:
    try:
        response = llm.invoke(
            performance_prompt.format_messages(code=state["code"]))
        return {"performance_analysis": response.content}
    except Exception as e:
        print(f"⚠️  Performance agent failed: {str(e)}")
        return {"performance_analysis": "Performance analysis failed - agent encountered an error"}


def style_agent(state: CodeAnalysisState) -> CodeAnalysisState:
    try:
        response = llm.invoke(style_prompt.format_messages(code=state["code"]))
        return {"style_analysis": response.content}
    except Exception as e:
        print(f"⚠️  Style agent failed: {str(e)}")
        return {"style_analysis": "Style analysis failed - agent encountered an error"}


def documentation_agent(state: CodeAnalysisState) -> CodeAnalysisState:
    try:
        response = llm.invoke(
            documentation_prompt.format_messages(code=state["code"]))
        return {"documentation_analysis": response.content}
    except Exception as e:
        print(f"⚠️  Documentation agent failed: {str(e)}")
        return {"documentation_analysis": "Documentation analysis failed - agent encountered an error"}


def synthesis_agent(state: CodeAnalysisState) -> CodeAnalysisState:
    start_time = time.time()

    response = llm.invoke(synthesis_prompt.format_messages(
        security=state["security_analysis"],
        performance=state["performance_analysis"],
        style=state["style_analysis"],
        documentation=state["documentation_analysis"]
    ))

    parallel_time = time.time() - start_time
    total_parallel_time = parallel_time + max(
        time.time() - start_time for _ in range(1)
    )

    sequential_time = state.get("sequential_time", 0)
    speedup = sequential_time / total_parallel_time if total_parallel_time > 0 else 0

    print(f"⏱️  Parallel execution completed")
    print(f"Sequential time: {sequential_time:.2f}s")
    print(f"Parallel time: {total_parallel_time:.2f}s")
    print(f"Speedup: {speedup:.2f}x")

    return {
        "final_report": response.content,
        "parallel_time": total_parallel_time
    }


builder = StateGraph(CodeAnalysisState)
builder.add_node("coder", coder_agent)
builder.add_node("security_agent", security_agent)
builder.add_node("performance_agent", performance_agent)
builder.add_node("style_agent", style_agent)
builder.add_node("documentation_agent", documentation_agent)
builder.add_node("synthesis", synthesis_agent)

builder.add_edge(START, "coder")
builder.add_edge("coder", "security_agent")
builder.add_edge("coder", "performance_agent")
builder.add_edge("coder", "style_agent")
builder.add_edge("coder", "documentation_agent")
builder.add_edge("security_agent", "synthesis")
builder.add_edge("performance_agent", "synthesis")
builder.add_edge("style_agent", "synthesis")
builder.add_edge("documentation_agent", "synthesis")
builder.add_edge("synthesis", END)

workflow = builder.compile()

if __name__ == "__main__":
    task = "Write a web API endpoint that processes user uploads and stores them in a database"

    print("Running parallel processing...")
    result = workflow.invoke({"input": task})

    codebase = ParallelCodebase("03_parallel_processing", task)
    codebase.generate(result)

    print("=== WORKFLOW COMPLETED ===")
